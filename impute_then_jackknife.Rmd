---
title: "R Notebook"
output: html_notebook
---

# Dependencies

```{r, message=FALSE}
library(mice)
library(MASS)
library(furrr)
library(purrr)
library(tidyverse)
library(parallel)
library(latex2exp)
library(reshape2)
library(miceFast)
library(tictoc)

options(future.rng.onMisuse = 'ignore')

```

# Data Simulation

## Defining data simulation function

```{r}
data_generator <- function(sample_size, seed, prop, desired_data){
  set.seed(seed)
  cor_mat <- matrix(c(1, 0.5, 0.5, 
                      0.5, 1, 0.5, 
                      0.5, 0.5, 1), nrow = 3, ncol = 3)
  
  mean_vec <- c(1, 1, 1)
  
  covariates <- as.data.frame(mvrnorm(sample_size, mu = mean_vec, Sigma = cor_mat))
  
  outcome_variable <- 4 + 
    2*covariates$V1 + 
    5*covariates$V2 +  
    8*covariates$V3 +
    rnorm(sample_size, 0, abs(covariates$V1)*2)
  
  data_complete <- cbind(outcome_variable, covariates)
  
  data_w_missing <- 
    suppressWarnings(
      ampute(data_complete, prop = prop, mech = "MAR", patterns = c(0, 1, 1, 1))$amp
    )
  return(get(desired_data))
  
}
```

## Creating data for simulation

```{r, eval = TRUE}
set.seed(971423)
N = 1e4
sample_size = 1e2
seed = 1:N
prop = 0.3
desired_data = "data_w_missing"

# Create list of data frames with missing 
plan(multisession)

list_of_sim_data <- 
  future_map(seed, ~data_generator(sample_size, .x, prop, desired_data))

# Obtains one of the data frames to be used for small prototyping. 

df_w_mis <- list_of_sim_data[[sample(1:N, 1, replace = TRUE)]]

# Function for drop-d-jackknife
choose.int <- function(x, n, k) {
  if(n <= k) return(rep(TRUE, k))
  u <- choose(n-1, k-1)
  pick <- x < u
  if (pick) y <- choose.int(x, n-1, k-1) else y <- choose.int(x-u, n-1, k)
  return(c(pick, y))
}
```

# Estimator Prototype 3
```{r}
jackknife_prototype_3 <- function(df_w_mis){
  m = 2
  imputations <- mice(df_w_mis, m = m, maxit = 2, method = "midastouch", print = FALSE) %>%
    complete("all")
  
  imputations_df_estimate <- imputations %>%
    lapply(lm, formula = outcome_variable ~ V1 + V2 + V3) %>%
    pool() %>%
    broom::tidy() %>%
    filter(term == "V1") %>%
    select("df") %>%
    unlist()
  
  n_sub_samples <- 500
  
  n = nrow(df_w_mis); k = 70
  
  length_sample_vec <- choose(n, k)
  
  if (length_sample_vec > 1e15) {
    length_sample_vec = 1e15
  } else {
    length_sample_vec = length_sample_vec
  }
  
  sample <- 
    sapply(sample.int(length_sample_vec, n_sub_samples, replace = FALSE)-1,
           choose.int, n=n, k=k)
  
  drop_d_subsamples <- lapply(1:number_of_imps, function(x)
    map(1:ncol(sample),
        ~as.matrix(imputations[[x]][sample[,.x],])))
  
  pseudo_estimates <- 
    map(drop_d_subsamples,
        ~vapply(.x, function(x) .lm.fit(x = x[,2:4], y = x[,1])$coefficients[1], numeric(1)))
  
  within_imp_var <- mean(vapply(pseudo_estimates, function(x) sd(x)/sqrt(length(x)), numeric(1)))
  between_imp_var <- mean(vapply(pseudo_estimates, var, numeric(1)))
  
  total_var <- within_imp_var + between_imp_var + between_imp_var/m
  total_se <- sqrt(total_var)
  
  point_estimates <- vapply(pseudo_estimates, mean, numeric(1))
  
  point_estimate <- mean(point_estimates)
  
  critical_value <- qt(p = 0.025, df = imputations_df_estimate, lower.tail = FALSE)
  
  bound <- critical_value*total_se
  
  LB <- point_estimate - bound
  UB <- point_estimate + bound
  
  return(data.frame("UB" = UB, 
                    "LB" = LB, 
                    "point_estimate" = point_estimate) %>%
           remove_rownames())
  
}
```

# Small Monte Carlo for Jackknife Estimator

```{r, eval = TRUE}
plan(multisession)

jackknife_var_estimates <- future_map_dfr(list_of_sim_data, jackknife_prototype_3)
```

# Small Monte Carlo for Rubin's Rules

```{r, eval = TRUE}
plan(multisession)

rubin_var_estimates <- 
  future_map_dfr(list_of_sim_data, 
                 ~mice(.x, seed = 123, print = FALSE, method = "pmm",
                       m = 10, maxit = 5) %>%
                   mice::complete("long") %>%
                   group_by(.imp) %>%
                   do(model = lm(outcome_variable ~ V1 + V2 + V3, data = .)) %>%
                   as.list() %>%
                   .[[-1]] %>%
                   pool() %>%
                   summary(conf.int = TRUE) %>%
                   as.data.frame() %>%
                   dplyr::filter(term == "V1") %>%
                   dplyr::select(c(estimate, "2.5 %", "97.5 %")) %>%
                   dplyr::rename(point_estimate_rub = estimate, 
                                 LB_rub = "2.5 %", 
                                 UB_rub = "97.5 %")) 
```

# MC for bootimpute 
```{r}
library(bootImpute)

boot_analyzer <- function(df_w_mis){
  boot_impute <- bootMice(df_w_mis, nBoot = 200, nImp = 2, nCores = 1, seed = 123, print = FALSE)
  boot_impute_mat <- lapply(boot_impute, as.matrix)
  
  point_estimates <- vapply(boot_impute_mat, function(x) .lm.fit(x = x[,2:4], y = x[,1])$coefficients[1], numeric(1))
  LB <- quantile(point_estimates, 0.025)
  UB <- quantile(point_estimates, 0.975)
  
  return(data.frame("UB_boot" = UB, 
                    "LB_boot" = LB, 
                    "point_estimate_boot" = mean(point_estimates)) %>%
           remove_rownames())
}

plan(multisession)

boot_estimates <- future_map_dfr(list_of_sim_data, boot_analyzer)
```


# Organizing Results

```{r, eval = TRUE}
combined_results <- cbind(true_var = 2, rubin_var_estimates, jackknife_var_estimates, boot_estimates) 

rubin_width <- combined_results$UB_rub - combined_results$LB_rub

jackknife_width <- combined_results$UB - combined_results$LB

boot_width <- combined_results$UB_boot - combined_results$LB_boot

combined_results <- cbind(combined_results, rubin_width, jackknife_width, boot_width)
```

# Analysis of Results

```{r, eval = TRUE}
# Jackknife coverage probability
round((sum(combined_results$true_var < combined_results$UB & combined_results$true_var > combined_results$LB) / nrow(combined_results))*100,2)

# Coverage: 
# Jackknife -> 96 
# Boot -> 70
# Rubin -> 88

reshape2::melt(combined_results[c("point_estimate_rub", "point_estimate", "point_estimate_boot")]) %>%
  ggplot(data = .,
         aes(x = value, fill = variable, color = variable)) + 
  geom_density(aes(y = ..density..), alpha = 0.25) + 
  theme(axis.title.y = element_blank(), 
        panel.spacing=unit(1.5,"lines")) + 
  theme_bw() + 
  theme(axis.title.y = element_blank(), 
        panel.spacing=unit(1.5,"lines"), 
        strip.text = element_text(
          size = 9)) + 
  labs(
    x = latex2exp::TeX("$\\widehat{\\beta_1}")
  ) 

ggplot(combined_results, aes(x = c(1:nrow(combined_results)))) + 
  geom_point(aes(y = point_estimate, color = "red")) +
  geom_point(aes(y = 2, alpha = 0.1)) + 
  geom_errorbar(aes(ymin = LB, ymax = UB, alpha = 0.01)) + 
  coord_flip() + 
  theme_bw() + 
  labs(
    x = latex2exp::TeX("$i^{th} dataset"), 
    y = latex2exp::TeX("$\\widehat{\\sigma^2}")
  ) + 
  theme(legend.position="none") + 
  geom_hline(yintercept = combined_results$true_var)
```
# NULL # 
We had the most appropriate coverage; however, also had somewhat large CI. Also, our point estimates seem to be centered between Rubin and Bootstrap, (how to interpret?) 

All had bad-is point estimates, but reasonable given heteroskedastic errors. (Isn't OLS point estimator unbiased under heteroskedastic errors?)


### Trash Can 
```{r}
bound <- qnorm(0.025, mean = 0, sd = 1, lower.tail = FALSE)*sqrt(var(pseudo_estimates_trimmed)/nrow(df_w_mis))

LB_var <- jackknife_point_estimate - bound  
UB_var <- jackknife_point_estimate + bound
```







